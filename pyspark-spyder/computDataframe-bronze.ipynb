# -*- coding: utf-8 -*-
"""
Editor Spyder

Análise de Dados com editor spyder
para visualização das métricas futuras
e databricks com pyspark na criação do 
cluster.

"""

"""

 

#Define número fixo de partições para shuffle melhorando o paralelismo
#Define o tamanho máximo de partições evitando arquivos pequenos
#Usa o codec Snappy para compreensão rápida otimizando o tempo de leitura e escrita
#Hibilita otimizações adaptativas ajustando o número de partições dinamicamente com base no tamanho dos dados
  

"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
from pyspark.sql import Row
from pyspark.sql.functions import col
from pyspark.sql.functions import when

# Criando a sessão do Spark
spark = SparkSession.builder \
    .appName("Load Data bronze") \
    .config("spark.sql.shuffle.partitions", "200") \
    .config("spark.sql.files.maxPartitionsBytes", "128MB") \
    .config("spark.sql.parquet.compression.codec", "snappy") \
    .config("spark.sql.adaptive.enable", "true") \
    .getOrCreate()

# Criando dados
dados = [
    Row(id=1, valor1=10, valor2=20),
    Row(id=2, valor1=30, valor2=40),
    Row(id=3, valor1=50, valor2=60),
]

# Criando um DataFrame
df = spark.createDataFrame(dados)

# Exibindo o DataFrame
df.show()



#criando nova coluna e atribuindo soma
df_new_column = df.withColumn("soma", col("valor1") + col("valor2"))
df_new_column.show()

df_classificacao = df_new_column.withColumn(
    "classificacao",
    when(col("soma") > 50, "Alto").otherwise("Baixo")
)

df_classificacao.show()
"""

DEFININDO ARMAZENAMENTO NO DATALAKE

**spark.sql.shuffle.partitions**= define n de partições
**spark.s...files.maxPartitionsBytes= define o tamanho máximo dos pequenos
**...parquet.compression.codec**= descompressão eficiente dos dados
**...adaptative.enable**= ajusta o plano automaticamente


calc para n/partições=núcle_cpu*2 ou 3 (faz spark usar todos núcleos disponíveis)


"""


lz_path_in = "/mnt/lhdw/landingzone/vendas/processar"
lz_path_out = "/mnt/lhdw/landingzone/vendas/processado"
bronze_path = "/mnt/lhdw/bronze/vendas"



# listar arquivos em um diretório
dbutils.fs.ls("/dbfs/tmp/")

# verificar se um diretório existe
dbutils.fs.mkdirs("/dbfs/tmp/novo_diretorio")

# copiar um arquivo de um diretório para outro
dbutils.fs.cp("/dbfs/tmp/exemplo_parquet", "/dbfs/tmp/novo_diretorio/exemplo_parquet", True)

# mover um arquivo para outro diretório
dbutils.fs.mv("/dbfs/tmp/novo_diretorio/exemplo_parquet", "/dbfs/tmp/exemplo_parquet_moved", True)

# remover um arquivo ou diretório
dbutils.fs.rm("/dbfs/tmp/novo_diretorio", True)

# exibir conteúdo de um arquivo texto
with open("/dbfs/tmp/exemplo_parquet/part-00000-...") as f:
    print(f.read())

